{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spanemo.learner import Trainer\n",
    "from spanemo.model import SpanEmo\n",
    "from spanemo.data_loader import DataClass\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "seed = 12345678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if str(device) == 'cuda:0':\n",
    "    print(\"Currently using GPU: {}\".format(device))\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    print(\"WARNING: USING CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loaders(args):\n",
    "    train_dataset = DataClass(args, args['train_path'])\n",
    "\n",
    "\n",
    "    train_data_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=int(args['train_batch_size']),\n",
    "                                  shuffle=True\n",
    "                                  )\n",
    "    print('The number of training batches: ', len(train_data_loader))\n",
    "\n",
    "    val_dataset = DataClass(args, args['val_path'])\n",
    "    val_data_loader = DataLoader(val_dataset,\n",
    "                                batch_size=int(args['val_batch_size']),\n",
    "                                shuffle=False\n",
    "                                )\n",
    "    print('The number of validation batches: ', len(val_data_loader))\n",
    "\n",
    "    return train_data_loader, val_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(args):\n",
    "    model = SpanEmo(output_dropout=args['output_dropout'],\n",
    "                    backbone=args['backbone'],\n",
    "                    joint_loss=args['loss_type'],\n",
    "                    alpha=args['alpha_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(args):\n",
    "\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    filename = now.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "    fw = open('configs/' + filename + '.json', 'a')\n",
    "    json.dump(args, fw, sort_keys=True, indent=2)\n",
    "\n",
    "    train_data_loader, val_data_loader = make_loaders(args)\n",
    "    model = make_model(args)\n",
    "\n",
    "    learn = Trainer(model, train_data_loader, val_data_loader, filename=filename)\n",
    "    learn.fit(\n",
    "        num_epochs=int(args['max_epoch']),\n",
    "        args=args,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'train_path':'data/train.csv', \n",
    "    'val_path':'data/val.csv',\n",
    "    'backbone':'bert-base-uncased',\n",
    "    'train_batch_size': 32,\n",
    "    'val_batch_size': 32,\n",
    "    'output_dropout': 0.1,\n",
    "    'loss_type': 'joint',\n",
    "    'alpha_loss': 0.2,\n",
    "    'max_epoch': 20,\n",
    "    'max_length': 128,\n",
    "    'ffn_lr': 0.001,\n",
    "    'bert_lr': 2e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexlu/miniconda3/envs/emo/lib/python3.9/site-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter_2018 - 1grams ...\n",
      "Reading twitter_2018 - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexlu/miniconda3/envs/emo/lib/python3.9/site-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter_2018 - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PreProcessing dataset ...:   0%|          | 0/43410 [00:00<?, ?it/s]/home/alexlu/miniconda3/envs/emo/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "PreProcessing dataset ...:  41%|████▏     | 18012/43410 [00:14<00:20, 1244.03it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pipeline(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spanemo.learner import Trainer\n",
    "from spanemo.model import SpanEmo\n",
    "from spanemo.data_loader import DataClass\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "seed = 12345678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if str(device) == 'cuda:0':\n",
    "    print(\"Currently using GPU: {}\".format(device))\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    print(\"WARNING: USING CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loaders(args):\n",
    "    train_dataset = DataClass(args, args['train_path'])\n",
    "\n",
    "\n",
    "    train_data_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=int(args['train_batch_size']),\n",
    "                                  shuffle=True\n",
    "                                  )\n",
    "    print('The number of training batches: ', len(train_data_loader))\n",
    "\n",
    "    val_dataset = DataClass(args, args['val_path'])\n",
    "    val_data_loader = DataLoader(val_dataset,\n",
    "                                batch_size=int(args['val_batch_size']),\n",
    "                                shuffle=False\n",
    "                                )\n",
    "    print('The number of validation batches: ', len(val_data_loader))\n",
    "\n",
    "    return train_data_loader, val_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(args):\n",
    "    model = SpanEmo(output_dropout=args['output_dropout'],\n",
    "                    backbone=args['backbone'],\n",
    "                    joint_loss=args['loss_type'],\n",
    "                    alpha=args['alpha_loss'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(args, loaders=None):\n",
    "\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    filename = now.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "    fw = open('configs/' + filename + '.json', 'a')\n",
    "    json.dump(args, fw, sort_keys=True, indent=2)\n",
    "\n",
    "    if loaders is None:\n",
    "        train_data_loader, val_data_loader = make_loaders(args)\n",
    "    else:\n",
    "        train_data_loader, val_data_loader = loaders\n",
    "    model = make_model(args)\n",
    "\n",
    "    learn = Trainer(model, train_data_loader, val_data_loader, filename=filename)\n",
    "    learn.fit(\n",
    "        num_epochs=int(args['max_epoch']),\n",
    "        args=args,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'train_path':'data/train.csv', \n",
    "    'val_path':'data/val.csv',\n",
    "    'backbone':'bert-base-uncased',\n",
    "    'train_batch_size': 128,\n",
    "    'val_batch_size': 128,\n",
    "    'output_dropout': 0.1,\n",
    "    'loss_type': 'joint',\n",
    "    'alpha_loss': 0.2,\n",
    "    'max_epoch': 20,\n",
    "    'max_length': 128,\n",
    "    'ffn_lr': 0.001,\n",
    "    'bert_lr': 2e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexlu/miniconda3/envs/emo/lib/python3.9/site-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter_2018 - 1grams ...\n",
      "Reading twitter_2018 - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexlu/miniconda3/envs/emo/lib/python3.9/site-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter_2018 - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PreProcessing dataset ...:   0%|          | 0/43410 [00:00<?, ?it/s]/home/alexlu/miniconda3/envs/emo/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "PreProcessing dataset ...: 100%|██████████| 43410/43410 [00:39<00:00, 1088.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training batches:  340\n",
      "Reading twitter_2018 - 1grams ...\n",
      "Reading twitter_2018 - 2grams ...\n",
      "Reading twitter_2018 - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PreProcessing dataset ...:   0%|          | 0/5426 [00:00<?, ?it/s]/home/alexlu/miniconda3/envs/emo/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "PreProcessing dataset ...: 100%|██████████| 5426/5426 [00:05<00:00, 1041.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of validation batches:  43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loaders = make_loaders(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/alexlu/miniconda3/envs/emo/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='13' class='' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      65.00% [13/20 39:05&lt;21:02]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Train_Loss</th>\n",
       "      <th>Val_Loss</th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Micro</th>\n",
       "      <th>JS</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.3004</td>\n",
       "      <td>0.2076</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.5601</td>\n",
       "      <td>0.5038</td>\n",
       "      <td>03:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.2026</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.5118</td>\n",
       "      <td>0.6024</td>\n",
       "      <td>0.5571</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.1901</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>0.5403</td>\n",
       "      <td>0.6152</td>\n",
       "      <td>0.5721</td>\n",
       "      <td>03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.1823</td>\n",
       "      <td>0.1884</td>\n",
       "      <td>0.5370</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>03:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.1757</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.5343</td>\n",
       "      <td>0.6113</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>03:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.1683</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>0.5762</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.1961</td>\n",
       "      <td>0.5335</td>\n",
       "      <td>0.6001</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.2019</td>\n",
       "      <td>0.5299</td>\n",
       "      <td>0.5905</td>\n",
       "      <td>0.5563</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.5927</td>\n",
       "      <td>0.5603</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.1391</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.5169</td>\n",
       "      <td>0.5718</td>\n",
       "      <td>0.5386</td>\n",
       "      <td>03:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.1332</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.5801</td>\n",
       "      <td>0.5487</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.5164</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>0.5409</td>\n",
       "      <td>02:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.1239</td>\n",
       "      <td>0.2265</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>0.5422</td>\n",
       "      <td>02:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='43' class='' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [43/43 00:07&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch#:  1\n",
      "Validation loss decreased (inf --> 0.207630).  Saving model ...\n",
      "epoch#:  2\n",
      "Validation loss decreased (0.207630 --> 0.193123).  Saving model ...\n",
      "epoch#:  3\n",
      "Validation loss decreased (0.193123 --> 0.190322).  Saving model ...\n",
      "epoch#:  4\n",
      "Validation loss decreased (0.190322 --> 0.188408).  Saving model ...\n",
      "epoch#:  5\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch#:  6\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch#:  7\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch#:  8\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch#:  9\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch#:  10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "epoch#:  11\n",
      "EarlyStopping counter: 7 out of 10\n",
      "epoch#:  12\n",
      "EarlyStopping counter: 8 out of 10\n",
      "epoch#:  13\n",
      "EarlyStopping counter: 9 out of 10\n",
      "epoch#:  14\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "#wooooooooooooooooooooo\n",
    "pipeline(hyperparams, loaders=loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

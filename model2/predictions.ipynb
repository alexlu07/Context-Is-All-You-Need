{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from model1.spanemo.model import SpanEmo\n",
    "from model1.spanemo.data_loader import DataClass\n",
    "from fastprogress.fastprogress import format_time, master_bar, progress_bar\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cornell_movie/predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.3</th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>utterance text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>u0</td>\n",
       "      <td>L1044</td>\n",
       "      <td>-8.052365</td>\n",
       "      <td>-8.175057</td>\n",
       "      <td>-6.226021</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.333762</td>\n",
       "      <td>-8.336207</td>\n",
       "      <td>-7.862222</td>\n",
       "      <td>-8.547613</td>\n",
       "      <td>-6.139152</td>\n",
       "      <td>-8.437870</td>\n",
       "      <td>-8.259851</td>\n",
       "      <td>-7.689548</td>\n",
       "      <td>-8.167355</td>\n",
       "      <td>2.519341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>They do to!</td>\n",
       "      <td>u2</td>\n",
       "      <td>L1044</td>\n",
       "      <td>-7.363643</td>\n",
       "      <td>-7.539609</td>\n",
       "      <td>-6.305096</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.726948</td>\n",
       "      <td>-8.030384</td>\n",
       "      <td>-6.329423</td>\n",
       "      <td>-8.293463</td>\n",
       "      <td>-5.284000</td>\n",
       "      <td>-7.944016</td>\n",
       "      <td>-8.296870</td>\n",
       "      <td>-7.327426</td>\n",
       "      <td>-7.314297</td>\n",
       "      <td>3.753215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>I hope so.</td>\n",
       "      <td>u0</td>\n",
       "      <td>L984</td>\n",
       "      <td>-7.674916</td>\n",
       "      <td>-8.189976</td>\n",
       "      <td>-8.220063</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.028004</td>\n",
       "      <td>-8.382309</td>\n",
       "      <td>3.741410</td>\n",
       "      <td>-8.533669</td>\n",
       "      <td>-7.790706</td>\n",
       "      <td>-8.272712</td>\n",
       "      <td>-8.568789</td>\n",
       "      <td>-8.038083</td>\n",
       "      <td>-8.474198</td>\n",
       "      <td>-5.249081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>She okay?</td>\n",
       "      <td>u2</td>\n",
       "      <td>L984</td>\n",
       "      <td>-7.802964</td>\n",
       "      <td>-8.037459</td>\n",
       "      <td>-7.943669</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.027291</td>\n",
       "      <td>-7.490631</td>\n",
       "      <td>-7.594229</td>\n",
       "      <td>-8.463768</td>\n",
       "      <td>-7.411293</td>\n",
       "      <td>-6.965907</td>\n",
       "      <td>-8.347673</td>\n",
       "      <td>-7.013407</td>\n",
       "      <td>-7.727482</td>\n",
       "      <td>0.628213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Let's go.</td>\n",
       "      <td>u0</td>\n",
       "      <td>L924</td>\n",
       "      <td>-7.713368</td>\n",
       "      <td>-7.858588</td>\n",
       "      <td>-6.787925</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.113943</td>\n",
       "      <td>-8.096422</td>\n",
       "      <td>-5.721414</td>\n",
       "      <td>-8.452881</td>\n",
       "      <td>-5.515314</td>\n",
       "      <td>-8.016721</td>\n",
       "      <td>-8.270496</td>\n",
       "      <td>-7.152738</td>\n",
       "      <td>-7.782495</td>\n",
       "      <td>3.867799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164680</th>\n",
       "      <td>164680</td>\n",
       "      <td>164680</td>\n",
       "      <td>164680</td>\n",
       "      <td>164901</td>\n",
       "      <td>Sell maps?</td>\n",
       "      <td>u4749</td>\n",
       "      <td>L153138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164681</th>\n",
       "      <td>164681</td>\n",
       "      <td>164681</td>\n",
       "      <td>164681</td>\n",
       "      <td>164902</td>\n",
       "      <td>Only two bucks.  Shave as well...</td>\n",
       "      <td>u4739</td>\n",
       "      <td>L153132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164682</th>\n",
       "      <td>164682</td>\n",
       "      <td>164682</td>\n",
       "      <td>164682</td>\n",
       "      <td>164903</td>\n",
       "      <td>Thanks.  Just some pills.</td>\n",
       "      <td>u4749</td>\n",
       "      <td>L153132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164683</th>\n",
       "      <td>164683</td>\n",
       "      <td>164683</td>\n",
       "      <td>164683</td>\n",
       "      <td>164904</td>\n",
       "      <td>Looks like you need a haircut to me.</td>\n",
       "      <td>u4739</td>\n",
       "      <td>L153132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164684</th>\n",
       "      <td>164684</td>\n",
       "      <td>164684</td>\n",
       "      <td>164684</td>\n",
       "      <td>164905</td>\n",
       "      <td>I need something to keep me awake.</td>\n",
       "      <td>u4749</td>\n",
       "      <td>L153132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164685 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0.3  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  \\\n",
       "0                  0             0             0           0   \n",
       "1                  1             1             1           1   \n",
       "2                  2             2             2           2   \n",
       "3                  3             3             3           3   \n",
       "4                  4             4             4           4   \n",
       "...              ...           ...           ...         ...   \n",
       "164680        164680        164680        164680      164901   \n",
       "164681        164681        164681        164681      164902   \n",
       "164682        164682        164682        164682      164903   \n",
       "164683        164683        164683        164683      164904   \n",
       "164684        164684        164684        164684      164905   \n",
       "\n",
       "                              utterance text speaker conversation_id  \\\n",
       "0                               They do not!      u0           L1044   \n",
       "1                                They do to!      u2           L1044   \n",
       "2                                 I hope so.      u0            L984   \n",
       "3                                  She okay?      u2            L984   \n",
       "4                                  Let's go.      u0            L924   \n",
       "...                                      ...     ...             ...   \n",
       "164680                            Sell maps?   u4749         L153138   \n",
       "164681     Only two bucks.  Shave as well...   u4739         L153132   \n",
       "164682             Thanks.  Just some pills.   u4749         L153132   \n",
       "164683  Looks like you need a haircut to me.   u4739         L153132   \n",
       "164684    I need something to keep me awake.   u4749         L153132   \n",
       "\n",
       "               0         1         2  ...        18        19        20  \\\n",
       "0      -8.052365 -8.175057 -6.226021  ... -8.333762 -8.336207 -7.862222   \n",
       "1      -7.363643 -7.539609 -6.305096  ... -7.726948 -8.030384 -6.329423   \n",
       "2      -7.674916 -8.189976 -8.220063  ... -8.028004 -8.382309  3.741410   \n",
       "3      -7.802964 -8.037459 -7.943669  ... -8.027291 -7.490631 -7.594229   \n",
       "4      -7.713368 -7.858588 -6.787925  ... -8.113943 -8.096422 -5.721414   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "164680       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "164681       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "164682       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "164683       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "164684       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "\n",
       "              21        22        23        24        25        26        27  \n",
       "0      -8.547613 -6.139152 -8.437870 -8.259851 -7.689548 -8.167355  2.519341  \n",
       "1      -8.293463 -5.284000 -7.944016 -8.296870 -7.327426 -7.314297  3.753215  \n",
       "2      -8.533669 -7.790706 -8.272712 -8.568789 -8.038083 -8.474198 -5.249081  \n",
       "3      -8.463768 -7.411293 -6.965907 -8.347673 -7.013407 -7.727482  0.628213  \n",
       "4      -8.452881 -5.515314 -8.016721 -8.270496 -7.152738 -7.782495  3.867799  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "164680       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "164681       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "164682       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "164683       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "164684       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[164685 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 12345678\n",
    "\n",
    "if str(device) == 'cuda:0':\n",
    "    print(\"Currently using GPU: {}\".format(device))\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    print(\"WARNING: USING CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_dict = {\n",
    "    \"cornell\": \"cornell_movie/predictions.csv\",\n",
    "    \"iemocap\": \"iemocap/predictions.csv\", #do ur stuff here\n",
    "    \"another\": \"another_df/predictions.csv\", # do ur stuff here\n",
    "}\n",
    "\n",
    "df_dict = {\n",
    "    \"cornell\": pd.read_csv(paths_dict[\"cornell\"]),\n",
    "    \"iemocap\": None,\n",
    "    \"another\": None,\n",
    "}\n",
    "\n",
    "text_dict = {\n",
    "    \"cornell\": np.array(df_dict[\"cornell\"][\"utterance text\"]),\n",
    "    \"iemocap\": np.array(0) # whatever\n",
    "}\n",
    "\n",
    "dataset_name = \"cornell\"\n",
    "data_path = paths_dict[dataset_name]\n",
    "pred_df = df_dict[dataset_name]\n",
    "text_arr = text_dict[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'backbone':'bert-base-uncased',\n",
    "    'max_length': 128, #maximum context length for the model\n",
    "    'batch_size': 128,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpanEmo(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (ffn): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"../model1/final_model.pt\"\n",
    "model = SpanEmo()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter_2018 - 1grams ...\n",
      "Reading twitter_2018 - 2grams ...\n",
      "Reading twitter_2018 - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PreProcessing dataset ...: 100%|██████████| 32768/32768 [00:27<00:00, 1175.01it/s]\n"
     ]
    }
   ],
   "source": [
    "x = 32768\n",
    "i = 0\n",
    "dataset = DataClass(hyperparams, text_arr[i*x:i*x+x], pred_mode=True)\n",
    "data_loader = DataLoader(dataset,\n",
    "                        batch_size=hyperparams['batch_size'],\n",
    "                        shuffle=False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    current_index = 0\n",
    "    for step, batch in enumerate(progress_bar(data_loader, parent=None, leave=False)):\n",
    "        if step < index:\n",
    "            current_index += hyperparams['batch_size']\n",
    "            continue\n",
    "\n",
    "        num_rows, y_pred, logits = model.predict(batch, device)\n",
    "        \n",
    "        pred_df.iloc[i*x + current_index: i*x + current_index + num_rows, pred_df.columns.get_loc(\"0\"):] = logits.cpu().numpy()\n",
    "        if step % 10 == 0 and step > 0: pred_df.to_csv(data_path)\n",
    "        \n",
    "        current_index += num_rows\n",
    "\n",
    "pred_df.to_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(start=0, x=32768):\n",
    "    model_path = \"../model1/final_model.pt\"\n",
    "    model = SpanEmo()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    mb = master_bar(range(start, math.ceil(len(pred_df)/x)))\n",
    "    for i in mb:\n",
    "        dataset = DataClass(hyperparams, \n",
    "                            text_arr[i*x : min(i*x+x, len(pred_df))], \n",
    "                            pred_mode=True, \n",
    "                            pbar=lambda x, **kw: progress_bar(x, parent=mb, leave=False))\n",
    "        data_loader = DataLoader(dataset,\n",
    "                                batch_size=hyperparams['batch_size'],\n",
    "                                shuffle=False\n",
    "                                )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            current_index = 0\n",
    "            for step, batch in enumerate(progress_bar(data_loader, parent=mb, leave=False)):\n",
    "                num_rows, y_pred, logits = model.predict(batch, device)\n",
    "                \n",
    "                pred_df.iloc[i*x + current_index: i*x + current_index + num_rows, pred_df.columns.get_loc(\"0\"):] = logits.cpu().numpy()\n",
    "                if step % 16 == 0 and step > 0: pred_df.to_csv(data_path)\n",
    "                \n",
    "                current_index += num_rows\n",
    "\n",
    "        pred_df.to_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='2' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.00% [2/10 03:17&lt;13:09]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='256' class='' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [256/256 01:11&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter_2018 - 1grams ...\n",
      "Reading twitter_2018 - 2grams ...\n",
      "Reading twitter_2018 - 1grams ...\n",
      "Reading twitter_2018 - 1grams ...\n",
      "Reading twitter_2018 - 2grams ...\n",
      "Reading twitter_2018 - 1grams ...\n",
      "Reading twitter_2018 - 1grams ...\n",
      "Reading twitter_2018 - 2grams ...\n",
      "Reading twitter_2018 - 1grams ...\n",
      "Reading twitter_2018 - 1grams ...\n",
      "Reading twitter_2018 - 2grams ...\n"
     ]
    }
   ],
   "source": [
    "loop(start=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

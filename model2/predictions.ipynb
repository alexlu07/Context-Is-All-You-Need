{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from model1.spanemo.model import SpanEmo\n",
    "from model1.spanemo.data_loader import DataClass\n",
    "from fastprogress.fastprogress import format_time, master_bar, progress_bar\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 12345678\n",
    "\n",
    "if str(device) == 'cuda:0':\n",
    "    print(\"Currently using GPU: {}\".format(device))\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    print(\"WARNING: USING CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_dict = {\n",
    "    \"cornell\": \"cornell_movie/predictions.csv\",\n",
    "    \"iemocap\": \"iemocap/predictions.csv\", #do ur stuff here\n",
    "    \"another\": \"another_df/predictions.csv\", # do ur stuff here\n",
    "}\n",
    "\n",
    "df_dict = {\n",
    "    \"cornell\": pd.read_csv(paths_dict[\"cornell\"]),\n",
    "    \"iemocap\": None,\n",
    "    \"another\": None,\n",
    "}\n",
    "\n",
    "text_dict = {\n",
    "    \"cornell\": np.array(df_dict[\"cornell\"][\"utterance text\"]),\n",
    "    \"iemocap\": np.array(0) # whatever\n",
    "}\n",
    "\n",
    "dataset_name = \"cornell\"\n",
    "data_path = paths_dict[dataset_name]\n",
    "pred_df = df_dict[dataset_name]\n",
    "text_arr = text_dict[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'backbone':'bert-base-uncased',\n",
    "    'max_length': 128, #maximum context length for the model\n",
    "    'batch_size': 128,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexlu/miniconda3/envs/emo/lib/python3.9/site-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter_2018 - 1grams ...\n",
      "Reading twitter_2018 - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexlu/miniconda3/envs/emo/lib/python3.9/site-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter_2018 - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PreProcessing dataset ...:   0%|          | 0/32768 [00:00<?, ?it/s]/home/alexlu/miniconda3/envs/emo/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "PreProcessing dataset ...: 100%|██████████| 32768/32768 [00:27<00:00, 1184.30it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = DataClass(hyperparams, text_arr[0:32768], pred_mode=True)\n",
    "data_loader = DataLoader(dataset,\n",
    "                        batch_size=hyperparams['batch_size'],\n",
    "                        shuffle=False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"../model1/final_model.pt\"\n",
    "model = SpanEmo()\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/256 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_232140/2232872937.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['prediction'][current_index: current_index + num_rows, :] = logits.cpu().numpy()\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'key of type tuple not found and not a MultiIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/emo/lib/python3.9/site-packages/pandas/core/series.py:1105\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1105\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_with_engine(key, value)\n\u001b[1;32m   1106\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m     \u001b[39m# We have a scalar (or for MultiIndex or object-dtype, scalar-like)\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m     \u001b[39m#  key that is not present in self.index.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/emo/lib/python3.9/site-packages/pandas/core/series.py:1175\u001b[0m, in \u001b[0;36mSeries._set_with_engine\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_with_engine\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1175\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   1177\u001b[0m     \u001b[39m# this is equivalent to self._values[key] = value\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/emo/lib/python3.9/site-packages/pandas/core/indexes/range.py:394\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[1;32m    395\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "File \u001b[0;32m~/miniconda3/envs/emo/lib/python3.9/site-packages/pandas/core/indexes/base.py:5925\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5922\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5923\u001b[0m     \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5924\u001b[0m     \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5925\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(0, 128, None), slice(None, None, None))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/alexlu/Documents/Programming/alexlu07/Scires/11th/model2/predictions.ipynb Cell 8\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B69.124.5.1/home/alexlu/Documents/Programming/alexlu07/Scires/11th/model2/predictions.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B69.124.5.1/home/alexlu/Documents/Programming/alexlu07/Scires/11th/model2/predictions.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m num_rows, y_pred, logits \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(batch, device)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B69.124.5.1/home/alexlu/Documents/Programming/alexlu07/Scires/11th/model2/predictions.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m pred_df[\u001b[39m'\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m'\u001b[39m][current_index: current_index \u001b[39m+\u001b[39m num_rows, :] \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B69.124.5.1/home/alexlu/Documents/Programming/alexlu07/Scires/11th/model2/predictions.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: pred_df\u001b[39m.\u001b[39mto_csv(data_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B69.124.5.1/home/alexlu/Documents/Programming/alexlu07/Scires/11th/model2/predictions.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m current_index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m num_rows\n",
      "File \u001b[0;32m~/miniconda3/envs/emo/lib/python3.9/site-packages/pandas/core/series.py:1138\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidIndexError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1135\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# cases with MultiIndex don't get here bc they raise KeyError\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# e.g. test_basic_getitem_setitem_corner\u001b[39;00m\n\u001b[0;32m-> 1138\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m   1139\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mkey of type tuple not found and not a MultiIndex\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1140\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m     \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m   1143\u001b[0m         key \u001b[39m=\u001b[39m check_bool_indexer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'key of type tuple not found and not a MultiIndex'"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    current_index = 0\n",
    "    for step, batch in enumerate(progress_bar(data_loader, parent=None, leave=False)):\n",
    "        if step < current_index:\n",
    "            current_index += hyperparams['batch_size']\n",
    "            continue\n",
    "        num_rows, y_pred, logits = model.predict(batch, device)\n",
    "        pred_df['prediction'][current_index: current_index + num_rows, :] = logits.cpu().numpy()\n",
    "        if step % 10 == 0: pred_df.to_csv(data_path)\n",
    "        current_index += num_rows\n",
    "\n",
    "pred_df.to_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
